Volumes in k8s

With volumes, the data generated by the pod is now stored 
in the volume mounted on the pod. Even after the pod is deleletd
the data remains. The data stays on the node storage where the 
volume is pointing to.


Within the spec section we define the volume and its storage.
On the container section we speficy the where on the container
is the volume being mounted on.
For instance if the container is writting a number to a specific
path, we mount the volume to that path so its replicated to
the storage we want.

----------------------------------------------------------------

Persistent Volume

- Cluster-wide pool of storage volumes, to be used by users
deploying apps on the cluster. 
The users can select storage from that pool, using
claims. So they are doing Persistant Volume Claims (PVC)

to create:

apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-vol1
spec:
  accessModes:
  - ReadWriteOnce -- 
  capacity:
     storage: 1Gb
  hostPath:  #volume type
    path: /aaa/aaa

kubectl apply -f yaml
kubectl get persistentvolume


---------------------------------------------------------------

Persistant Volume Claims

- a separate resource

K8s binds PV to to the PVC. it searches for properties on the PV
to match the PVC.

to create: 

apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: myclaim
spec:
  accessModes:
  - ReadWriteOnce -- 
  resources:
    requests:
      storage: 500Mb

kubectl apply -f yaml
kubectl get persistentvolumeclaim


You can choose what happens to the PV when the PVC is deleted. 
Retain, deleted, or recycled

These are then to be used on a pod definition file under the 
persistentVolumeClaim section: 

apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  containers:
  - name: myfrontend
    image: nginx
    volumeMounts:
    - mountPath: "/var/www/html"
    name: mypd
  volumes:
  - name: mypd
    persistentVolumeClaim:
      claimName: myclaim 



----------------------------------------------------------------------------

Dynamic Provisioning

- To automate volume provisioning (create the actual storage on the end resource),
we use Storage Classes

you can define a provisioner that can automatically provision storage on the cloud
and mount it on the pod.

By using StorageClasses we longer need the pv definition file, since the pv
is automatically created when attaching the SC on the PVC


sc-definition.yaml

only need to add the SC name on PVC definition file:

storageClassName: xxx

then the pod uses the PVC 


apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: storage

provisioner: kubernetes.io/gce-pd

parameters:
  type:
  replication-type: 


its useful to use different kind of storages pretty quickly



